---
title: "Data and Power Simulations"
subtitle: "Presentation for SNS Retreat 2024"
author: "Emmanuel Guizar Rosales"
date-format: "[last rendered on:] MMM D, YYYY"
format: 
  revealjs: 
    toc: false
    toc-depth: 3
    slide-number: true
    number-sections: false
    smaller: true
    scrollable: true
    incremental: true
    code-fold: true
    code-annotations: hover
    theme: default
editor: visual
editor_options: 
  chunk_output_type: console
---

```{r}
#| label: setup

# install package librarian if needed
if (!("librarian" %in% rownames(installed.packages()))) {
  install.packages("librarian")
}

# load required packages
librarian::shelf(
  tidyverse,
  faux,
  lme4,
  lmerTest,
  ggdist,
  sjPlot,
  DT,
  broom.mixed,
  BlakeRMills/MetBrewer,
  simr
)
```

# Introduction

## Statistical Power

-   **Definition of Statistical Power**
    -   Statistical power is the probability that a test will correctly reject a false null hypothesis (i.e., detect an effect when there is one).
    -   It is usually denotes as $1-\beta$, where $\beta$ is the Type II error rate ( the probability of failing to reject a false null hypothesis).
-   **Importance of Statistical Power**
    -   High power reduces the risk of Type II errors.
    -   Ensures that studies are capable of detecting meaningful effects.
    -   Important for the credibility and reliability of research findings.

## Factors Affecting Statistical Power (1/2)

-   **Sample Size**
    -   Larger sample sizes increase power.
    -   Practical considerations: resources, time, and feasibility.
-   **Effect Size**
    -   Larger effect sizes are easier to detect, leading to higher power.
    -   Different effect sizes exist for different types of analyses. Many of them can be converted between each other. [(Effect size converter)](https://www.escal.site/){preview-link="true"}

## Factors Affecting Statistical Power (2/2)

-   **Significance Level (**$\alpha$)
    -   Commonly set at 0.05, but lower alpha values (e.g., 0.01) reduce power.
    -   Trade-off between Type I error (false positive) and Type II error (false negative).
-   **Variance**
    -   Lower variance within data increases power.
    -   Methods to reduce variance include controlling for confounding variables and improving measurement precision.

## Power Analysis (1/2)

-   **Purpose of Power Analysis**
    -   Determine the sample size needed to achieve a desired power level for detecting a given effect size.
    -   Can be conducted before (a priori) or after (post hoc) a study.
-   **Steps in Conducting Power Analysis**
    -   Define the significance level (α).
    -   Estimate the effect size (based on literature or pilot studies).
    -   Choose the desired power level (traditionally 80%, more recently: 90% or 95%).
    -   Whenever possible, use power analysis tools/software (e.g., G\*Power, R) to calculate the required sample size (much easier).

## Power Analyses (2/2)

-   **Types of Power Analysis**
    -   *A priori*: Conducted before data collection to ensure adequate sample size.
    -   *Post hoc*: Conducted after the study to determine the achieved power, often used for interpreting non-significant results.
    -   *Sensitivity analysis*: Determines the smallest effect size that can be detected with a given sample size and power.

## Power Analyses and Simulations

-   Not every power analysis requires simulations

-   For simple cases like t-tests, ANOVAs, correlations, multiple regressions, etc. there are **analytical** solutions for calculating power analyses (e.g., [G\*Power](https://www.psychologie.hhu.de/arbeitsgruppen/allgemeine-psychologie-und-arbeitspsychologie/gpower){preview-link="true"})

-   For more complex study designs, analytical solutions are difficult or impossible (e.g., situations with multiple interacting factors, non-standard distributions or assumptions, missing data...)

-   Focus on **multi-level models**: analytical solutions for power analyses are too complex (or have not even been derived yet).\
    → **Simulations**

# Excursus: Multi-Level Models

## Multi-Level Models (1/4)

-   Alternative Terms

    -   Multi-level models = hierarchical linear models (HLM) = mixed-effects models
    -   Multi-level models ≠ hierarchical regression

-   **Multi-level models have superior power (over, e.g., t-test with data aggregated over trials) when analyzing data that has a nested or hierarchical structure.**

-   These models account for the fact that data points within groups are often more similar to each other than to data points in other groups.

## Multi-Level Models (2/4)

-   Benefits
    -   **Correct Standard Errors:** Multi-level models account for the non-independence of observations within clusters, providing more accurate standard errors and significance tests.
    -   **Partitioning Variance:** They allow for the partitioning of variance at different levels (e.g., variance between individuals, within individuals, between trials, ...), helping to identify where variability in the outcome lies.
    -   **Modeling Complex Relationships:** These models can include fixed effects (constant, average effect of an explanatory variable on the outcome) and random effects (account for variability across different levels in the data).

## Multi-Level Models (3/4)

-   Typical examples in psychology:
    -   Nested data structures: Students nested within schools (educational psychology, clinical psychology, cultural differences research, etc.)

    -   Repeated measures: Participants complete multiple trials which differ in some attributes.\
        E.g., participants complete 25 trials which differ in the combination of bonus and carbon outcomes.

## Multi-Level Models (4/4)

[![](https://bookdown.org/steve_midway/DAR/images/07_models.png){fig-alt="Fixed effect, mixed effects, and random effects linear regression models." fig-align="center" width="790"}](https://bookdown.org/steve_midway/DAR/random-effects.html#types-of-models-with-random-effects)

# Simulate Data to Conduct Power Analyses

## Power Simulations: Procedure

1.  Think about the **Data Generating Process** (also very useful on a conceptual level!)

2.  Define the parameters:

    1.  sample sizes (subjects, trials),

    2.  sizes for fixed and random effects (including residual (error) variance)

    3.  significance level

3.  Generate a data set using the Data Generating Process

4.  Analyse the data set (fit your model to the data) and store the p value of your effect(s) of interest.

5.  Repeat steps 3 and 4 for a sufficient number of times (e.g., 1000 iterations).

6.  Count the number of analyses with significant results (true positives) and divide it by the total number of analyses (i.e., iterations) = **Power**

## Example: EcoTRACE Project

-   **Primary Question:**\
    Does political orientation affect how individual search for, process, and integrate information during climate-relevant decision-making? (process-tracing measures as dependent variables)

-   **Secondary Questions:**\
    Do the occurrence of extreme weather events and participants' attribution of such events to climate change moderate the effect of political orientation on process-tracing measures?

-   **Methods**

    -   Online process-tracing using mouselabWEB ([Try EcoTRACE](http://localhost/EcoTRACE_06/XX_startPage.php?subject=S001&condnum=0){preview-link="true"})

    -   Representative US sample (total N = 1'100)

    -   [Storm events database](https://www.ncdc.noaa.gov/stormevents/){preview-link="true"}: detailed record of extreme weather events on US county level

## Challenge

-   Conduct an *a priori* power analysis for planning and preregistering the study **without pilot data** (→ Simulations)

-   **Main Question:**\
    How many participants and trials do we need to reach 95% power to detect the smallest effect size of interest (SESOI)?

-   **Follow up question:**\
    How do different parameters affect the power to detect the SESOI?

    -   Number of participants

    -   Number of trials

    -   SESOI

    -   Random effects (intercepts and slopes)

    -   Noise in the data

## Data Generating Process (1/3)

-   Primary question: *Does participants' political orientation affect how much time they spend gathering information regarding carbon relative to bonus outcomes of their choice?*\
    \
    $$
    \Delta Duration = \frac{(t_{A\_Carbon} + t_{B\_Carbon}) - (t_{A\_Bonus} + t_{B\_Bonus})}{t_{A\_Carbon} + t_{B\_Carbon} + t_{A\_Bonus} + t_{B\_Bonus}}
    $$

-   Simpler question: *Does participants' political orientation affect how much time they spend on gathering information regarding carbon outcomes of their choice?*\
    ($t_{A\_Carbon} + t_{B\_Carbon}$)

## Data Generating Process (2/3)

**Assumptions**

-   The mean time spent on gathering carbon information, irrespective of participants' political orientation, is 3.5 seconds. → **fixed intercept = 3.5**

-   On average, Democrats spend 0.2 seconds longer on gathering carbon information than Republicans. That is, the mean effect of political orientation on dwell time on carbon information is 0.2 seconds. → **fixed effect of polOri = 0.2**

-   Subjects differ from the two group means (Republican or Democrat). This difference is normally distributed with a mean of 0 and a standard deviation of 0.5 seconds. → **by-subject random intercept SD = 0.5**

-   Within subjects, trials differ from each subjects mean dwell time. This difference is normally distributed with a mean of 0 and a standard deviation of 0.5 seconds. → **by-item random intercept SD = 0.5**

-   The noise (error) in the data is normally distributed with a mean of 0 and a standard deviation of 0.1 → **random error SD = 0.1**

## Excursus: Faux

::: nonincremental
Very helpful package for everything related to data simulation: [faux](https://debruine.github.io/faux/){preview-link="true"}

::: panel-tabset
### `add_random()`

```{r}
#| label: faux_addRandom
#| echo: true
#| code-fold: false

# 
add_random(subj = 4, trial = 2) # <1>
```

1.  Generate data fully crossing 4 subjects with 2 trials each.

### `add_between()`

```{r}
#| label: faux_addBetween
#| echo: true
#| code-fold: false
#| code-line-numbers: "2-3"

add_random(subj = 4, trial = 2) %>% 
  add_between("subj", polOri = c("rep", "dem"), .prob = 4*c(.5, .5), .shuffle = FALSE) %>%  # <1>
  add_contrast("polOri", contrast = "anova") #<2>
```

1.  Add a between subjects factor political orientation with levels "rep" and "dem". Both levels should be assigned with equal probability. The levels should not be shuffled.
2.  ANOVA-contrast-code the factor polOri (so that the intercept will indicate the grand mean).

<!-- ### `add_within()` -->

<!-- ```{r} -->

<!-- #| label: faux_addWithin -->

<!-- #| echo: true -->

<!-- #| code-fold: false -->

<!-- #| code-line-numbers: "3" -->

<!-- add_random(subj = 4, trial = 2) %>%  -->

<!--   add_between("subj", polOri = c("rep", "dem"), .prob = 4*c(.5, .5), .shuffle = FALSE) %>%  -->

<!--   add_within("subj", levelTemptation = c("easy", "hard")) # <1> -->

<!-- ``` -->

<!-- 1. Add a factor within sujects that asigns a temptetion level for each trial. -->

### `add_ranef()`

```{r}
#| label: faux_addRanef
#| echo: true
#| code-fold: false
#| code-line-numbers: "4-6"

add_random(subj = 4, trial = 2) %>% 
  add_between("subj", polOri = c("rep", "dem"), .prob = 4*c(.5, .5), .shuffle = FALSE) %>% 
  add_contrast("polOri", contrast = "anova") %>% 
  add_ranef("subj", bySubjectRandomIntercept = 2) %>% # <1>
  add_ranef("trial", byTrialRandomIntercept = 1) %>% # <2>
  add_ranef(error = 0.5) %>%  # <3>
  select(subj, trial, starts_with("by"), error)
```

1.  Add the by-subject random intercept with a SD = 2 (normally distributed).
2.  Add the by-trial random intercept with a SD = 1 (normally distributed).
3.  Add a random residual (error) with SD = 0.5 (normally distributed).

### calculate DV

Formula: `dv ~ polOri + (1|subj) + (1|trial)`

```{r}
#| label: faux_calculateDV
#| echo: true
#| code-fold: false
#| code-line-numbers: "10-15"
#| output: false

fixedEff_intercept <- 8
fixedEff_polOri <- 0.5

add_random(subj = 4, trial = 2) %>% 
  add_between("subj", polOri = c("rep", "dem"), .prob = 4*c(.5, .5), .shuffle = FALSE) %>% 
  add_contrast("polOri", contrast = "anova") %>% 
  add_ranef("subj", bySubjectRandomIntercept = 2) %>%
  add_ranef("trial", byTrialRandomIntercept = 1) %>%
  add_ranef(error = 0.5) %>% 
  mutate(
    dv = 
      fixedEff_intercept + bySubjectRandomIntercept + byTrialRandomIntercept + # <1>
      fixedEff_polOri * `polOri.dem-rep` + # <2>
      error # <3>
  )
```

1.  Add fixed and random intercepts.
2.  Add fixed effect of polOri.
3.  Add random error term.
:::
:::

## Data Generating Process (3/3)

```{r}
#| label: dataGeneratingProcess
#| echo: true
#| code-fold: false

# define data simulation function
FUN_sim_dtCarbon <- function(
  n_subj       =         50, # number of subjects
  n_subj_prop  =  c(.5, .5), # proportion of republican and democrat subjects
  n_trial      =         25, # number of trials
  beta_0       =        3.5, # intercept (grand mean) for dwell time (dt) carbon
  beta_p       =        .20, # effect of political orientation on dt carbon
  subj_0       =        .50, # by-subject random intercept sd for dt carbon
  trial_0      =        .50, # by-trial random intercept sd
  sigma        =        .10, # residual (error) sd
  
  truncNegNums =       TRUE # should negative number be truncuated at zero?
) {
  
  # simulate data for dwell time on carbon information
  dataSim <- 
    # add random factor subject
    add_random(subj = n_subj) %>%
    # add random factor trial
    add_random(trial = n_trial) %>%
    # add between-subject factor political orientation (with anova contrast)
    add_between("subj", polOri = c("rep", "dem"), .prob = n_subj_prop*n_subj, .shuffle = FALSE) %>% 
    add_contrast("polOri", colnames = "X_p", contrast = "anova") %>% 
    # add by-subject random intercept
    add_ranef("subj", S_0 = subj_0) %>% 
    # add by-trial random intercept
    add_ranef("trial", T_0 = trial_0) %>% 
    # add error term
    add_ranef(e_st = sigma) %>% 
    # add response values
    mutate(
      # add together fixed and random effects for each effect
      B_0 = beta_0 + S_0 + T_0,
      B_p = beta_p,
      # calculate dv by adding each effect term multiplied by the relevant
      # effect-coded factors and adding the error term
      dwellTime = B_0 + (B_p * X_p) + e_st
    )
  
  # truncuate negative dwell times
  if(truncNegNums) {
    dataSim <- dataSim %>% 
      mutate(dwellTime = if_else(dwellTime < 0, 0, dwellTime))
  }
  
  # run a linear mixed effects model
  mod <- lmer(
    dwellTime ~ polOri + (1 | subj) + (1 | trial),
    data = dataSim
  )
  
  # get results in tidy format
  mod.broom <- broom.mixed::tidy(mod)
  
  return(list(
    dataSim = dataSim,
    modelLmer = mod,
    modelResults = mod.broom
  ))
  
}
```

```{r}
#| label: dataGeneratingProcess_callFunction

# call the function
out_FUN_sim_dtCarbon <- FUN_sim_dtCarbon(
  n_subj       =         50, # number of subjects
  n_subj_prop  =  c(.5, .5), # proportion of republican and democrat subjects
  n_trial       =        25, # number of trials
  beta_0     =          3.5, # intercept (grand mean) for dwell time (dt) carbon
  beta_p     =          .20, # effect of political orientation on dt carbon
  subj_0     =          .50, # by-subject random intercept sd for dt carbon
  trial_0    =          .50, # by-trial random intercept sd
  sigma     =           .10, # residual (error) sd
  
  truncNegNums =       TRUE # should negative number be truncuated at zero?
)
```

## Data Simulation (1/2)

::: panel-tabset
### dataSim

```{r}
#| label: dataSimulation_results1

tmp <- out_FUN_sim_dtCarbon$dataSim
tmp %>% 
  datatable(
    options = list(pageLength = 5)
  ) %>% 
  formatRound(columns = names(tmp)[sapply(tmp, is.numeric)], digits = 2)
```

### modelResults

```{r}
#| label: dataSimulation_results2

tmp <- out_FUN_sim_dtCarbon$modelResults
tmp %>% 
  datatable() %>% 
  formatRound(columns = names(tmp)[sapply(tmp, is.numeric)], digits = 2)
```
:::

## Data Simulation (2/2)

Remember: We repeat the simulation of a data set a sufficient number of times (10 iterations in this example).

::: nonincremental
::: panel-tabset
### Code

```{r}
#| label: dataSimulation_iteration
#| echo: true
#| code-fold: false
#| code-line-numbers: "8-9"

FUN_powerSim <- function(rep) {
  sim <- FUN_sim_dtCarbon()$modelResults
  sim %>% 
    filter(term == "polOri.dem-rep") %>% 
    mutate(simulation = rep)
}

n_simulations <- 10
allSimulations <- map_df(1:n_simulations, FUN_powerSim) #<1>
```

1.  Apply the same function `n_simulations` times.

### Results

```{r}
#| label: dataSimulation_results3

tmp <- allSimulations
tmp %>% 
  datatable(
    options = list(pageLength = 3)
  ) %>% 
  formatRound(columns = names(tmp)[sapply(tmp, is.double)], digits = 3) %>% 
  formatStyle(columns = colnames(.), fontSize = "50%")
```

### Power

Remember: **Power** = number of significant results divided by number of all simulations.

We can calculate power as follows:

```{r}
#| echo: true
#| code-fold: false


res <- allSimulations %>% 
  select(simulation, p.value) %>% 
  mutate(significant = if_else(p.value < 0.05, 1, 0))
res
```

```{r}
#| echo: true
#| code-fold: false


sum(res$significant)/length(res$significant)
```

Equivalent but more elegant:

```{r}
#| echo: true
#| code-fold: false


mean(allSimulations$p.value < 0.05)
```
:::
:::

# Hand-On Data & Power Simulations

## Interactive Dashboard

Visit the following shiny application to conduct hands-on data & power simulations:

[https://eguizarrosales.shinyapps.io/dataAndPowerSimulations_dashboard_2/](https://eguizarrosales.shinyapps.io/dataAndPowerSimulations_dashboard_2/){target="_blank"}

## Data Simulation: Explanation (1/3)

In the first panel, each point represents a subject's the mean dwell time and the lines indicate ± 1 SD. Subjects are arranged in ascending order for mean dwell time, separately for [Republicans]{style="color:red;"} and [Democrats]{style="color:dodgerblue;"}.

![](../images/dashboard_subjects.png){fig-align="center"}

## Data Simulation: Explanation (2/3)

In the second panel, the data for [Republicans]{style="color:red;"} and [Democrats]{style="color:dodgerblue;"} are displayed on a group level using rain cloud plots.

![](../images/dashboard_groups.png){fig-align="center"}

## Data Simulation: Explanation (3/3)

In the results panel, the left table displays results of a mixed-model that was fitted with `lmer(dwellTime ~ polOri + (1|subj) + (1|trial), data)`. The right table displays results of a simple linear regression `lm(dwellTime ~ polOri, data_aggregated)`. Note that `data_aggregated` contains for each subject one dwell time aggregated over all trials. Also note that this analysis is equivalent to a simple t-test (with equal variances).

![](../images/dashboard_resultsTable.png){fig-align="center"}

## Power Simulation: Explanation (1/2)

The first panel shows the distribution of all fixed and random effects as estimated in the `N simulations`. The effect of Political Orientation is displayed in [blue]{style="color: #0e6ffd;"}.

![](../images/dashboard_distributionOfEffects.png){fig-align="center"}

## Power Simulation: Explanation (2/2)

The second panel shows a density plot for the p-values of the effect of Political Orientation. Note the negative logarithmic scale on the x-axis: higher values indicate lower p-values, i.e., more significant results. The area under the density curve for p-values greater than α are displayed in [red]{style="color: red;"}, p-values smaller than α in [green]{style="color: green;"}.

![](../images/dashboard_distributionOfPValues.png){fig-align="center"}

# Power Curves

## Power Curves (1/7)

-   One of the most prominent reasons to conduct power analyses is to determine **sample sizes**.

-   Power Curves plot sample size on the x-axis and calculated power to detect an effect of interest on the y-axis (example from G\*Power).

. . .

![](https://www.psychologie.hhu.de/fileadmin/redaktion/Fakultaeten/Mathematisch-Naturwissenschaftliche_Fakultaet/Psychologie/AAP/gpower/GPowerGraphWindow.png){fig-align="center" width="450"}

## Power Curves (2/7)

-   We can create power curves by repeatedly conducting power simulations for different sample sizes.

-   Additionally, it is insightful to also vary other parameters like the effect size or the alpha level.

## Power Curves (3/7)

::: panel-tabset
### Code

```{r}
#| label: powerCurves_allSims
#| echo: true
#| code-fold: false

# define parameters
sampleSizes <- c(50, 100)
effectSizes <- c(0.2, 0.3)
n_simulations <- 10

allSims <- tibble()
for (i in sampleSizes) {
  
  sims_otherParam <- tibble()
  for (j in effectSizes) {
    
    current_simulations <- tibble()
    for(k in 1:n_simulations) {
      sim <- FUN_sim_dtCarbon(
        n_subj       =          i, # number of subjects
        n_subj_prop  =  c(.5, .5), # proportion of republican and democrat subjects
        n_trial      =         25, # number of trials
        beta_0       =        3.5, # intercept (grand mean) for dwell time (dt) carbon
        beta_p       =          j, # effect of political orientation on dt carbon
        subj_0       =        .50, # by-subject random intercept sd for dt carbon
        trial_0      =        .50, # by-trial random intercept sd
        sigma        =        .10, # residual (error) sd
        
        truncNegNums =       TRUE # should negative number be truncuated at zero?
      )$modelResults %>% 
        filter(term == "polOri.dem-rep") %>% 
        mutate(
          sampleSize = i,
          effectSize = j,
          simulation = k
        )
      current_simulations <- rbind(current_simulations, sim)
    }
    
    sims_otherParam <- rbind(sims_otherParam, current_simulations)
  }
  
  allSims <- rbind(allSims, sims_otherParam)
}
```

### Output

```{r}
#| label: powerCurves_allSims_table

allSims %>% 
  select(sampleSize, effectSize, simulation, p.value) %>% 
  DT::datatable() %>% 
  formatRound(columns = "p.value", digits = 3)
```
:::

## Power Curves (4/7)

::: nonincremental
::: panel-tabset
### Code

```{r}
#| label: powerCurves_power
#| echo: true
#| code-fold: false


dataPower <- allSims %>% 
  group_by(sampleSize, effectSize) %>% 
  summarise(
    power = mean(p.value < 0.05),
    n = n(), #<1>
    x = power*n() #<2>
  ) %>% 
  # mutate(power_str = paste0(round(power * 100, 2), "%")) %>% 
  mutate(
    ci_lower = binom::binom.confint(x, n, .95, "exact")$lower,
    ci_upper = binom::binom.confint(x, n, .95, "exact")$upper
  ) %>% 
  mutate(across(
    .cols = c("power", "ci_lower", "ci_upper"),
    .fns = \(x) round(x * 100, 2),
    .names = "{.col}_prcnt"
  )) %>% 
  mutate(across(
    .cols = ends_with("prcnt"),
    .fns = \(x) paste0(format(x, nsmall = 2), "%"),
    .names = "{.col}_str"
  )) %>% 
  ungroup()
```

1.  number of simulations
2.  number of successses (significant p values)

### Output

```{r}
#| label: powerCurves_power_table
dataPower %>% 
  select(sampleSize, effectSize, ends_with("str")) %>% 
  DT::datatable()
```

### Generalized code

```{r}
#| label: powerCurves_function
#| echo: true
#| eval: false

# create a version of the main function that takes variable arguments
FUN_sim_dtCarbon_args <- function(...) {FUN_sim_dtCarbon(...)}

# create a function that can handle different parameters
FUN_multiSims <- function(
  sampleSizes      = c(50, 100),    # vector of sample sizes
  param_name       = "beta_p",      # name of the parameter that should be iterated over
  param_values     = c(0.2, 0.3),   # values of the parameter that should be iterated over
  n_simulations    = 10,            # number of simulations
  ...                               # additional arguments passed to FUN_sim_dtCarbon_args,
                                    # e.g., sigma = 1
) {
  
  allSims <- tibble()
  for (i in sampleSizes) {
    
    sims_otherParam <- tibble()
    for (j in param_values) {
      
      current_simulations <- tibble()
      for(k in 1:n_simulations) {
        
        # define list of arguments to be passed to FUN_multiSims
        
        # first define the arguments we iterate over 
        listOfArguments <- setNames(list(i, j), c("n_subj", param_name))
        # then define potential additional arguments that are passed by the ...
        listOfArguments <- c(listOfArguments, ...)
        
        # do the simulation, get the results for the effect of interest, and
        # add sample size, param name and value and number of simulation
        sim <- do.call(FUN_sim_dtCarbon_args, list(n_subj = i, beta_p = j))$modelResults %>% 
          filter(term == "polOri.dem-rep") %>% 
          mutate(
            sampleSize = i,
            param_name = param_name,
            param_value = j,
            simulation = k
          )
        current_simulations <- rbind(current_simulations, sim)
      }
      
      sims_otherParam <- rbind(sims_otherParam, current_simulations)
    }
    
    allSims <- rbind(allSims, sims_otherParam)
  }
  
  return(allSims)
  
}

out_FUN_multiSims <- FUN_multiSims(
  sampleSizes = seq(50, 200, 50),
  param_name = "beta_p",
  param_values = seq(.1, .3, .1),
  n_simulations = 1000
)
```

```{r}
#| label: powerCurves_function_out
#| echo: true

# read in simulations
out_FUN_multiSims_s1000 <- readRDS("../data/powerAnalyses/out_FUN_multiSims_s1000.RDS")

# read in simulations
out_FUN_multiSims_s100 <- readRDS("../data/powerAnalyses/out_FUN_multiSims_s100.RDS")

# define function to calculate power
FUN_multiSims_power <- function(sims, alpha = 0.05) {
  sims %>% 
    mutate(param_value = factor(param_value)) %>% 
    group_by(sampleSize, param_value) %>% 
    summarise(
      power = mean(p.value < alpha),
      n = n(),
      x = power*n()
    ) %>% 
    mutate(
      ci_lower = binom::binom.confint(x, n, .95, "exact")$lower,
      ci_upper = binom::binom.confint(x, n, .95, "exact")$upper
    ) %>% 
    mutate(across(
      .cols = c("power", "ci_lower", "ci_upper"),
      .fns = \(x) round(x * 100, 2),
      .names = "{.col}_prcnt"
    )) %>% 
    mutate(across(
      .cols = ends_with("prcnt"),
      .fns = \(x) paste0(format(x, nsmall = 2), "%"),
      .names = "{.col}_str"
    )) %>% 
    ungroup()
}

# define function to plot power curves
FUNPlotPowerCurve <- function(
  myData,
  myBreaks = seq(50, 200, 50),
  myLegendTitle = waiver(),
  myLegendLabels = waiver()
) {
  plot <- myData %>% 
    ggplot(aes(
      x = sampleSize,
      y = power,
      ymin = ci_lower,
      ymax = ci_upper,
      color = param_value,
      fill = param_value
    )) +
    geom_ribbon(alpha = .1, color = NA) +
    geom_errorbar(width = 1.5) +
    geom_line() +
    geom_point() +
    geom_hline(yintercept = .95, color = "grey70", linetype = "dashed") +
    scale_x_continuous(breaks = myBreaks) +
    scale_y_continuous(
      limits = c(0, 1),
      breaks = seq(0, 1, .05),
      labels = paste0(seq(0, 100, 5), "%")
    ) +
    ggthemes::scale_color_colorblind(labels = myLegendLabels) +
    ggthemes::scale_fill_colorblind(labels = myLegendLabels) +
    labs(
      x = "Number of Participants",
      y = "Power",
      color = myLegendTitle,
      fill = myLegendTitle
    ) +
    theme_bw() +
    theme(
      # legend.position = c(.875, .1),
      panel.grid.minor = element_blank(),
      panel.border = element_blank(),
      axis.line = element_line(color = "black")
    )
  return(plot)
}
```
:::
:::

## Power Curves (5/7)

```{r}
#| label: fig-powerCurveN1000Alpha05
#| echo: true
#| fig-width: 7

FUN_multiSims_power(
  sims = out_FUN_multiSims_s1000,
  alpha = 0.05
) %>% 
  FUNPlotPowerCurve(
    myLegendTitle = "Effect Size"
  ) +
  labs(title = "Power Curve for polOri (nSims = 1'000, alpha = 0.05)")
```

## Power Curves (6/7)

```{r}
#| label: fig-powerCurveN1000Alpha01
#| echo: true
#| fig-width: 7

FUN_multiSims_power(
  sims = out_FUN_multiSims_s1000,
  alpha = 0.01
) %>% 
  FUNPlotPowerCurve(
    myLegendTitle = "Effect Size"
  ) +
  labs(title = "Power Curve for polOri (nSims = 1'000, alpha = 0.01)")
```

## Power Curves (7/7)

```{r}
#| label: fig-powerCurveN100Alpha01
#| echo: true
#| fig-width: 7

FUN_multiSims_power(
  sims = out_FUN_multiSims_s100,
  alpha = 0.01
) %>% 
  FUNPlotPowerCurve(
    myLegendTitle = "Effect Size"
  ) +
  labs(title = "Power Curve for polOri (nSims = 100, alpha = 0.01)")
```

# `simr`

## `simr`

`simr` is a package that allows to conduct power simulations for mixed models. It works both for *a priori* power simulations **without** pilot data as well as (and even better) for *a priori* power simulations **with** pilot data.

The **advantages** of `simr` are that it is easier to use than doing power simulations yourself and it makes it also easy to generate power curves. Additionally, it is somewhat more optimized for efficient code execution.

The **disadvantages** of `simr` are that it less flexibel than your ifinitely customizable data and power simulations. It can also be less efficient in some respects. For instance, you only can only simulate power for one effect of your model at once (while we can save all effects of a model in one simulation in our custom simulations).

My recommendation: If you have pilot data, use `simr`. If you do not, do your own simulations.

# Thanks for your attention!